{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "piano-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "outdoor-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31552, 36) (13659, 35)\n",
      "(31552, 36) (13659, 35)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "data = pd.concat([train.drop('Occupation', axis = 1), test])\n",
    "data['Pay'] = data['Pay'].fillna(data['Pay'].mean())\n",
    "data['Sport Knowledge (in XP)'] = data['Sport Knowledge (in XP)'].fillna(data['Sport Knowledge (in XP)'].mean())\n",
    "data['Income Category'] = data['Income Category'].fillna(data['Income Category'].median())\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "X_train = data[:ntrain]\n",
    "y_train = train['Occupation']\n",
    "X_test = data[ntrain:]\n",
    "print(train.shape, test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "hidden-plastic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 35)\n"
     ]
    }
   ],
   "source": [
    "#Scaling using the Standard Scaler\n",
    "data = pd.concat([X_train, X_test])\n",
    "print(data.shape)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data = pd.DataFrame(scaler.fit_transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "metallic-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain= X_train.shape[0]\n",
    "X_train = data[:ntrain]\n",
    "X_test = data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "conditional-january",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31552</th>\n",
       "      <td>0.454393</td>\n",
       "      <td>0.065471</td>\n",
       "      <td>0.878370</td>\n",
       "      <td>-0.559037</td>\n",
       "      <td>-0.312095</td>\n",
       "      <td>-3.911383e-01</td>\n",
       "      <td>0.823773</td>\n",
       "      <td>-0.462724</td>\n",
       "      <td>-0.246916</td>\n",
       "      <td>1.493721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>-1.002902</td>\n",
       "      <td>1.002902</td>\n",
       "      <td>-1.026745</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>1.548892</td>\n",
       "      <td>-1.356030</td>\n",
       "      <td>1.572395</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31553</th>\n",
       "      <td>0.454393</td>\n",
       "      <td>1.623673</td>\n",
       "      <td>0.290741</td>\n",
       "      <td>-1.218254</td>\n",
       "      <td>1.311998</td>\n",
       "      <td>-3.179410e-01</td>\n",
       "      <td>0.823773</td>\n",
       "      <td>-0.159841</td>\n",
       "      <td>-0.246916</td>\n",
       "      <td>1.357919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>-1.002902</td>\n",
       "      <td>1.002902</td>\n",
       "      <td>-1.026745</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>1.548892</td>\n",
       "      <td>-1.356030</td>\n",
       "      <td>1.572395</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31554</th>\n",
       "      <td>-1.333168</td>\n",
       "      <td>0.288071</td>\n",
       "      <td>0.878370</td>\n",
       "      <td>-1.124080</td>\n",
       "      <td>1.311998</td>\n",
       "      <td>-3.372569e-01</td>\n",
       "      <td>0.823773</td>\n",
       "      <td>-0.470491</td>\n",
       "      <td>-0.246916</td>\n",
       "      <td>-0.631971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>-1.002902</td>\n",
       "      <td>1.002902</td>\n",
       "      <td>0.973952</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>-0.645623</td>\n",
       "      <td>-1.356030</td>\n",
       "      <td>1.572395</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31555</th>\n",
       "      <td>-0.439388</td>\n",
       "      <td>1.104273</td>\n",
       "      <td>1.465999</td>\n",
       "      <td>1.136095</td>\n",
       "      <td>-0.312095</td>\n",
       "      <td>-4.673855e-01</td>\n",
       "      <td>0.823773</td>\n",
       "      <td>1.005094</td>\n",
       "      <td>-0.246916</td>\n",
       "      <td>0.929407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>0.997107</td>\n",
       "      <td>-0.997107</td>\n",
       "      <td>0.973952</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>-0.645623</td>\n",
       "      <td>-1.356030</td>\n",
       "      <td>1.572395</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31556</th>\n",
       "      <td>1.348173</td>\n",
       "      <td>-0.305530</td>\n",
       "      <td>-1.472147</td>\n",
       "      <td>1.606965</td>\n",
       "      <td>-0.312095</td>\n",
       "      <td>-4.453585e-01</td>\n",
       "      <td>0.823773</td>\n",
       "      <td>-0.726776</td>\n",
       "      <td>-0.246916</td>\n",
       "      <td>0.468285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>0.997107</td>\n",
       "      <td>-0.997107</td>\n",
       "      <td>-1.026745</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>-0.645623</td>\n",
       "      <td>-1.356030</td>\n",
       "      <td>1.572395</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>1.348173</td>\n",
       "      <td>-0.491030</td>\n",
       "      <td>1.465999</td>\n",
       "      <td>3.207923</td>\n",
       "      <td>-1.936187</td>\n",
       "      <td>8.217008e-01</td>\n",
       "      <td>1.156344</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.190896</td>\n",
       "      <td>-1.192999</td>\n",
       "      <td>...</td>\n",
       "      <td>2.616824</td>\n",
       "      <td>-1.002902</td>\n",
       "      <td>1.002902</td>\n",
       "      <td>-1.026745</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>1.548892</td>\n",
       "      <td>0.737447</td>\n",
       "      <td>-0.635972</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>0.454393</td>\n",
       "      <td>-1.789532</td>\n",
       "      <td>-1.472147</td>\n",
       "      <td>-1.124080</td>\n",
       "      <td>1.311998</td>\n",
       "      <td>-2.101782e-01</td>\n",
       "      <td>1.156344</td>\n",
       "      <td>-0.078296</td>\n",
       "      <td>-0.246916</td>\n",
       "      <td>-0.404135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>-1.002902</td>\n",
       "      <td>1.002902</td>\n",
       "      <td>-1.026745</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>1.548892</td>\n",
       "      <td>0.737447</td>\n",
       "      <td>-0.635972</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>-2.449427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>-1.333168</td>\n",
       "      <td>-0.045829</td>\n",
       "      <td>-0.884518</td>\n",
       "      <td>-1.218254</td>\n",
       "      <td>1.311998</td>\n",
       "      <td>-3.611409e-13</td>\n",
       "      <td>1.156344</td>\n",
       "      <td>0.741042</td>\n",
       "      <td>1.504332</td>\n",
       "      <td>-1.264533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>-1.002902</td>\n",
       "      <td>1.002902</td>\n",
       "      <td>-1.026745</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>1.548892</td>\n",
       "      <td>0.737447</td>\n",
       "      <td>-0.635972</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>-1.333168</td>\n",
       "      <td>-1.270132</td>\n",
       "      <td>-1.472147</td>\n",
       "      <td>1.136095</td>\n",
       "      <td>-0.312095</td>\n",
       "      <td>-2.718537e-01</td>\n",
       "      <td>1.156344</td>\n",
       "      <td>-0.124893</td>\n",
       "      <td>1.504332</td>\n",
       "      <td>0.143917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>0.997107</td>\n",
       "      <td>-0.997107</td>\n",
       "      <td>-1.026745</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>1.548892</td>\n",
       "      <td>0.737447</td>\n",
       "      <td>-0.635972</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>-1.333168</td>\n",
       "      <td>1.067173</td>\n",
       "      <td>0.290741</td>\n",
       "      <td>-0.370689</td>\n",
       "      <td>-0.312095</td>\n",
       "      <td>5.373834e-01</td>\n",
       "      <td>1.156344</td>\n",
       "      <td>0.399328</td>\n",
       "      <td>4.569017</td>\n",
       "      <td>-0.220586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>0.997107</td>\n",
       "      <td>-0.997107</td>\n",
       "      <td>0.973952</td>\n",
       "      <td>-0.422608</td>\n",
       "      <td>-0.645623</td>\n",
       "      <td>0.737447</td>\n",
       "      <td>-0.635972</td>\n",
       "      <td>-0.262091</td>\n",
       "      <td>0.408259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13659 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4             5   \\\n",
       "31552  0.454393  0.065471  0.878370 -0.559037 -0.312095 -3.911383e-01   \n",
       "31553  0.454393  1.623673  0.290741 -1.218254  1.311998 -3.179410e-01   \n",
       "31554 -1.333168  0.288071  0.878370 -1.124080  1.311998 -3.372569e-01   \n",
       "31555 -0.439388  1.104273  1.465999  1.136095 -0.312095 -4.673855e-01   \n",
       "31556  1.348173 -0.305530 -1.472147  1.606965 -0.312095 -4.453585e-01   \n",
       "...         ...       ...       ...       ...       ...           ...   \n",
       "45206  1.348173 -0.491030  1.465999  3.207923 -1.936187  8.217008e-01   \n",
       "45207  0.454393 -1.789532 -1.472147 -1.124080  1.311998 -2.101782e-01   \n",
       "45208 -1.333168 -0.045829 -0.884518 -1.218254  1.311998 -3.611409e-13   \n",
       "45209 -1.333168 -1.270132 -1.472147  1.136095 -0.312095 -2.718537e-01   \n",
       "45210 -1.333168  1.067173  0.290741 -0.370689 -0.312095  5.373834e-01   \n",
       "\n",
       "             6         7         8         9   ...        25        26  \\\n",
       "31552  0.823773 -0.462724 -0.246916  1.493721  ... -0.382143 -1.002902   \n",
       "31553  0.823773 -0.159841 -0.246916  1.357919  ... -0.382143 -1.002902   \n",
       "31554  0.823773 -0.470491 -0.246916 -0.631971  ... -0.382143 -1.002902   \n",
       "31555  0.823773  1.005094 -0.246916  0.929407  ... -0.382143  0.997107   \n",
       "31556  0.823773 -0.726776 -0.246916  0.468285  ... -0.382143  0.997107   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "45206  1.156344  0.014899  0.190896 -1.192999  ...  2.616824 -1.002902   \n",
       "45207  1.156344 -0.078296 -0.246916 -0.404135  ... -0.382143 -1.002902   \n",
       "45208  1.156344  0.741042  1.504332 -1.264533  ... -0.382143 -1.002902   \n",
       "45209  1.156344 -0.124893  1.504332  0.143917  ... -0.382143  0.997107   \n",
       "45210  1.156344  0.399328  4.569017 -0.220586  ... -0.382143  0.997107   \n",
       "\n",
       "             27        28        29        30        31        32        33  \\\n",
       "31552  1.002902 -1.026745 -0.422608  1.548892 -1.356030  1.572395 -0.262091   \n",
       "31553  1.002902 -1.026745 -0.422608  1.548892 -1.356030  1.572395 -0.262091   \n",
       "31554  1.002902  0.973952 -0.422608 -0.645623 -1.356030  1.572395 -0.262091   \n",
       "31555 -0.997107  0.973952 -0.422608 -0.645623 -1.356030  1.572395 -0.262091   \n",
       "31556 -0.997107 -1.026745 -0.422608 -0.645623 -1.356030  1.572395 -0.262091   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "45206  1.002902 -1.026745 -0.422608  1.548892  0.737447 -0.635972 -0.262091   \n",
       "45207  1.002902 -1.026745 -0.422608  1.548892  0.737447 -0.635972 -0.262091   \n",
       "45208  1.002902 -1.026745 -0.422608  1.548892  0.737447 -0.635972 -0.262091   \n",
       "45209 -0.997107 -1.026745 -0.422608  1.548892  0.737447 -0.635972 -0.262091   \n",
       "45210 -0.997107  0.973952 -0.422608 -0.645623  0.737447 -0.635972 -0.262091   \n",
       "\n",
       "             34  \n",
       "31552  0.408259  \n",
       "31553  0.408259  \n",
       "31554  0.408259  \n",
       "31555  0.408259  \n",
       "31556  0.408259  \n",
       "...         ...  \n",
       "45206  0.408259  \n",
       "45207 -2.449427  \n",
       "45208  0.408259  \n",
       "45209  0.408259  \n",
       "45210  0.408259  \n",
       "\n",
       "[13659 rows x 35 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "green-diameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Occupation\n",
       "7             6772\n",
       "0             6617\n",
       "4             5276\n",
       "3             3594\n",
       "6             2917\n",
       "10            1582\n",
       "1             1112\n",
       "8             1050\n",
       "2              903\n",
       "9              861\n",
       "5              661\n",
       "11             207\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('clean/y_train.csv').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "found-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try averaging {random forest, xgboost, adaboost, lightgbm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "signal-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-02-18 23:17:04.366902'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "str(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "neither-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "classifier = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=16),\n",
    "    n_estimators=200\n",
    ")\n",
    "\n",
    "models = [\n",
    "    ('Random Forest' , RandomForestClassifier()),\n",
    "    ('Decision trees', DecisionTreeClassifier()),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    ('AdaBoost', classifier),\n",
    "    ('Light GBM', LGBMClassifier(objective = 'multiclass', num_class = 12, num_leaves = 42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "wound-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest ....\n",
      "(13659, 12)\n",
      "Model : Decision trees ....\n",
      "(13659, 12)\n",
      "Model : XGB ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachiket/.local/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(13659, 12)\n",
      "Model : AdaBoost ....\n",
      "(13659, 12)\n",
      "Model : Light GBM ....\n",
      "(13659, 12)\n"
     ]
    }
   ],
   "source": [
    "guesses = {}\n",
    "for name, model in models:\n",
    "    print(f'Model : {name} ....')\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_test)\n",
    "    guesses[name] = preds\n",
    "    print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "wired-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(name, preds):\n",
    "    test = pd.read_csv('clean/X_test.csv')\n",
    "    test = test['Id'].values\n",
    "    pd.DataFrame({\n",
    "        'Id' : test,\n",
    "        'Occupation' : preds\n",
    "    }).to_csv(f'avg_out/{name}_{str(datetime.datetime.now())[:-7]}_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "knowing-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05380478 0.00884541 0.01308324 0.29653566 0.18636165 0.00183074\n",
      " 0.14368303 0.28795849 0.00307493 0.00200422 0.00210101 0.00071683]\n"
     ]
    }
   ],
   "source": [
    "mods = ['Random Forest', 'XGB', 'AdaBoost', 'Light GBM']\n",
    "vals = []\n",
    "for model in mods:\n",
    "    vals.append(guesses[model])\n",
    "print(vals[3][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fewer-representative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37637080787145316, 0.056645586867838424, 0.013619689678645415, 0.03918188221613318, 0.14260366268570052, 0.0005461956636183936, 0.014699893317036871, 0.021270458424329484, 0.0835073795209572, 0.0007731329629958664, 0.0007209731766918371, 6.032556197576748e-05]\n",
      "[0.5259103804591844, 0.018402749658576856, 0.009296207603167328, 0.026796829068138562, 0.10865534583094169, 0.0002483024556306411, 0.009133989855430168, 0.02292037649682058, 0.021454805294086422, 0.006408236008080418, 0.0005234923942180117, 0.00024928860829115715]\n",
      "[0.5806748352137505, 0.021475598736263563, 0.006521711470653803, 0.02514231714196722, 0.07224786665977774, 0.00046822116190370366, 0.00853745082796245, 0.008791345305108226, 0.02458912072408658, 0.0014314600652550863, 9.615641227212465e-05, 2.3901694522897252e-05]\n",
      "[0.031519310695101346, 0.005731393697512949, 0.007177749864072317, 0.0763132692454047, 0.10602164923213818, 5.96585806974167e-05, 0.0871108051785149, 0.41857602195538324, 0.013747060273433033, 0.0030870882871699918, 0.0005333793569516935, 0.00012260840948264076]\n",
      "[0.01608926158636159, 0.019841914788542747, 0.02782368304372332, 0.016272863321540952, 0.016580055558135038, 2.604813726096362e-05, 0.0337984877673411, 0.5579237045470705, 0.01142172091935862, 0.035492496484169335, 0.013026366010596112, 0.0017033979941518456]\n",
      "[0.013428126828118902, 0.006758755692100719, 0.006974279406587179, 0.13523371188873531, 0.3362310732673717, 0.008459260812257669, 0.09081308534138968, 0.1445448888206888, 0.004973411306054063, 0.0022448209877734587, 0.00027972982607139346, 5.884686796627242e-05]\n",
      "[0.6060943702383053, 0.005790367870187751, 0.0077393488393012536, 0.007281055892909947, 0.09613695889502162, 0.0002644268256646788, 0.0050063324912612665, 0.003446113606657865, 0.007434165618173089, 0.010237687707200314, 7.317092503186147e-05, 0.0004959942308760043]\n",
      "[0.6287430582061297, 0.011879467539942902, 0.0018884107131418321, 0.003985806427487349, 0.0910365720180896, 8.823331548830121e-05, 0.0014401678264174182, 0.0010824779413077111, 0.005824658738108866, 0.003751044640232174, 7.233470657684688e-05, 0.00020777736854183377]\n",
      "[0.5094886388313893, 0.04588623850239401, 0.008101599970459356, 0.04341513149570657, 0.10542782347339098, 0.008071856343415243, 0.008107864662270514, 0.009408433373737443, 0.006901961323496282, 0.005120937718276194, 3.881773413757012e-05, 3.069844761412061e-05]\n",
      "[0.025866041918490606, 0.003551364611380621, 0.07227447410320623, 0.09240421787378802, 0.09015536385677969, 0.0002965001451626748, 0.08134720734158998, 0.3575447439746383, 0.00796369824044653, 0.018241628048671202, 0.0001865086035246286, 0.00016825161701547407]\n",
      "[0.0130348432941129, 0.005280742440102945, 0.00718186652125196, 0.20770669480878368, 0.09917489496709073, 0.005006212949928932, 0.07280169165906811, 0.33052419974252145, 0.0076336729089900935, 0.0015496774505975271, 7.130180745620138e-05, 3.420783656727266e-05]\n",
      "[0.007995394008679678, 0.010380555174829548, 0.007592040272210952, 0.0739163506113199, 0.11106711933415742, 0.0004359679443469624, 0.11624418297491106, 0.4016899500705279, 0.008433791229168786, 0.011966896670339077, 0.00024878535858965646, 2.8953262380773147e-05]\n",
      "[0.014129336357203287, 0.006664328050718159, 0.016686357291762224, 0.20810760210557078, 0.1010554935879948, 0.11948032559252961, 0.10980070774971593, 0.1686399946274949, 0.0020872637836551948, 0.0031105935504702423, 0.00016799933581547908, 7.000604883932278e-05]\n",
      "[0.012421420122179918, 0.0017046344119414198, 0.0023590526083480867, 0.01460825213236955, 0.01797230945892051, 1.6716999579732883e-05, 0.0004940859645534105, 0.002412289225144693, 0.0040086299637260665, 0.00550153393481432, 0.6878097668199377, 0.0006913087286489997]\n"
     ]
    }
   ],
   "source": [
    "mods = ['XGB', 'AdaBoost', 'Light GBM']\n",
    "vals = []\n",
    "for model in mods:\n",
    "    vals.append(guesses[model])\n",
    "\n",
    "ans = []\n",
    "    \n",
    "for sample_id in range(13659):\n",
    "    sums = [0 for _ in range(12)]\n",
    "    for mod_id in range(len(mods)):\n",
    "        for p in range(12):\n",
    "            sums[p] += vals[mod_id][sample_id][p]\n",
    "    sums = [sum / 4 for sum in sums]\n",
    "    if sample_id % 1000 == 0:\n",
    "        print(sums)\n",
    "    ans.append(np.argmax(sums))\n",
    "sub('AVG', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "criminal-mexican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13659"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ans).value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-period",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
